{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":792972,"sourceType":"datasetVersion","datasetId":1636}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %pip install pandas\n# %pip install numpy\n# %pip install matplotlib\n# %pip install seaborn\n# %pip install scikit-surprise\n# %pip install joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nfrom surprise import Dataset, Reader, SVD\nfrom surprise.model_selection import cross_validate, train_test_split\nfrom surprise import accuracy\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to read a single data file and return a DataFrame\ndef read_data_file(file_path):\n    data_list = []\n    with open(file_path, 'r') as file:\n        current_movie_id = None\n        for line in file:\n            line = line.strip()\n            if line.endswith(':'):\n                current_movie_id = int(line.replace(':', ''))\n            else:\n                customer_id, rating, date = line.split(',')\n                data_list.append([int(customer_id), current_movie_id, float(rating), date])\n    return pd.DataFrame(data_list, columns=['Cust_Id', 'Movie_Id', 'Rating', 'Date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to filter out inactive users based on the specified quantile threshold\ndef filter_active_users(ratings, quantile_threshold=0.7):\n    ratings_count = ratings['Cust_Id'].value_counts()\n    active_users = ratings_count[ratings_count >= ratings_count.quantile(quantile_threshold)].index\n    return ratings[ratings['Cust_Id'].isin(active_users)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to prepare data for the Surprise library\ndef prepare_data_for_surprise(ratings):\n    reader = Reader(rating_scale=(1, 5))\n    return Dataset.load_from_df(ratings[['Cust_Id', 'Movie_Id', 'Rating']], reader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of combined data files\ndata_files = [\n    'combined_data_1.txt',\n    'combined_data_2.txt',\n    'combined_data_3.txt',\n    'combined_data_4.txt'\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data from the first file for training\ntrain_ratings_1 = read_data_file(os.path.join('/kaggle/input/netflix-prize-data/', data_files[0]))\n\n# Load data from the second file for training\ntrain_ratings_2 = read_data_file(os.path.join('/kaggle/input/netflix-prize-data/', data_files[1]))\n\n# Concatenate training data\ntrain_ratings = pd.concat([train_ratings_1, train_ratings_2])\n\nprint(train_ratings.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_ratings_1\ndel train_ratings_2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter inactive users from training data\ntrain_ratings = filter_active_users(train_ratings)\nprint(train_ratings.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic statistics for training data\nprint(train_ratings.describe())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rating distribution\nplt.figure(figsize=(10, 6))\nsns.countplot(data=train_ratings, x='Rating', palette='viridis')\nplt.title('Rating Distribution')\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of ratings per movie\nratings_per_movie = train_ratings.groupby('Movie_Id').size()\nplt.figure(figsize=(10, 6))\nplt.hist(ratings_per_movie, bins=50, color='purple')\nplt.title('Number of Ratings per Movie')\nplt.xlabel('Number of Ratings')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of ratings per user\nratings_per_user = train_ratings.groupby('Cust_Id').size()\nplt.figure(figsize=(10, 6))\nplt.hist(ratings_per_user, bins=50, color='orange')\nplt.title('Number of Ratings per User')\nplt.xlabel('Number of Ratings')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare training data for the Surprise library\ntrain_data = prepare_data_for_surprise(train_ratings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_ratings","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the training data into train and validation sets\ntrainset, valset = train_test_split(train_data, test_size=0.25)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the SVD model\nalgo = SVD(n_epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the SVD model\nalgo.fit(trainset)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nval_predictions = algo.test(valset)\nval_rmse = accuracy.rmse(val_predictions)\nval_mae = accuracy.mae(val_predictions)\nprint(f'Validation RMSE: {val_rmse}, Validation MAE: {val_mae}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear unnecessary data structures to free up memory\ndel trainset\ndel valset\ndel val_predictions\n\nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the trained model to a file\nmodel_filename = 'svd_model.joblib'\njoblib.dump(algo, model_filename)\nprint(f\"Model saved to {model_filename}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved model\nmodel_filename = 'svd_model.joblib'\nalgo = joblib.load(model_filename)\nprint(\"Model loaded successfully\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load additional data files\ntrain_ratings_3 = read_data_file(os.path.join('/kaggle/input/netflix-prize-data/', data_files[2]))\ntrain_ratings_4 = read_data_file(os.path.join('/kaggle/input/netflix-prize-data/', data_files[3]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the additional data with the existing training data\nadditional_ratings = pd.concat([train_ratings_3, train_ratings_4])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_ratings_3\ndel train_ratings_4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter inactive users from additional training data\nadditional_ratings = filter_active_users(additional_ratings)\nprint(additional_ratings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic statistics for additional data\nprint(additional_ratings.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rating distribution\nplt.figure(figsize=(10, 6))\nsns.countplot(data=additional_ratings, x='Rating', palette='viridis')\nplt.title('Rating Distribution')\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of ratings per movie\nratings_per_movie = additional_ratings.groupby('Movie_Id').size()\nplt.figure(figsize=(10, 6))\nplt.hist(ratings_per_movie, bins=50, color='purple')\nplt.title('Number of Ratings per Movie')\nplt.xlabel('Number of Ratings')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of ratings per user\nratings_per_user = additional_ratings.groupby('Cust_Id').size()\nplt.figure(figsize=(10, 6))\nplt.hist(ratings_per_user, bins=50, color='orange')\nplt.title('Number of Ratings per User')\nplt.xlabel('Number of Ratings')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare additional data for the Surprise library\nadditional_data = prepare_data_for_surprise(additional_ratings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del additional_ratings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the additional data into train and validation sets\nadditional_trainset, additional_valset = train_test_split(additional_data, test_size=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del additional_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model incrementally with additional data\nalgo.fit(additional_trainset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the additional validation set\nadditional_val_predictions = algo.test(additional_valset)\nadditional_val_rmse = accuracy.rmse(additional_val_predictions)\nadditional_val_mae = accuracy.mae(additional_val_predictions)\nprint(f'Additional Validation RMSE: {additional_val_rmse}, Additional Validation MAE: {additional_val_mae}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear unnecessary data structures to free up memory\ndel additional_trainset\ndel additional_valset\n\nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the updated model\nupdated_model_filename = 'svd_model_updated.joblib'\njoblib.dump(algo, updated_model_filename)\nprint(f\"Updated model saved to {updated_model_filename}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\n# Path to the model file\nmodel_filename = 'svd_model_updated.joblib'\n\n# Name of the zip file\nzip_filename = 'svd_model.zip'\n\n# Create a zip file and add the model file to it\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    zipf.write(model_filename)\n\nprint(f\"Model has been zipped and saved as {zip_filename}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved model\nupdated_model_filename = 'svd_model_updated.joblib'\nalgo = joblib.load(model_filename)\nprint(\"Model loaded successfully\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get top-N recommendations for a user\ndef get_top_n_recommendations(algo, user_id, movie_ids, n=10):\n    # Create a list of (movie_id, predicted_rating) for all movies\n    predictions = [algo.predict(user_id, str(movie_id)) for movie_id in movie_ids]\n    \n    # Sort the predictions by estimated rating in descending order\n    top_n_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n    \n    # Extract the movie IDs and estimated scores from the top-N predictions\n    top_n_movie_ids = [int(pred.iid) for pred in top_n_predictions]\n    top_n_scores = [pred.est for pred in top_n_predictions]\n    \n    return top_n_movie_ids, top_n_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load movie titles with custom parser to handle inconsistent number of columns\ndef read_movie_titles(file_path):\n    movie_titles = []\n    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n        for line in file:\n            parts = line.strip().split(',', 2)\n            if len(parts) == 3:\n                movie_id, year, name = parts\n                try:\n                    movie_id = int(movie_id)\n                except ValueError:\n                    continue\n                if year == 'NULL':\n                    year = None\n                else:\n                    try:\n                        year = int(year)\n                    except ValueError:\n                        continue\n                movie_titles.append([movie_id, year, name])\n    return pd.DataFrame(movie_titles, columns=['Movie_Id', 'Year', 'Name'])\n\nmovie_titles = read_movie_titles('/kaggle/input/netflix-prize-data/movie_titles.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all movie IDs from the movie titles dataset\nall_movie_ids = movie_titles['Movie_Id'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the qualifying dataset\ndef read_qualifying_file(file_path):\n    qualifying_data = []\n    current_movie_id = None\n    with open(file_path, 'r') as file:\n        for line in file:\n            line = line.strip()\n            if line.endswith(':'):\n                current_movie_id = int(line.replace(':', ''))\n            else:\n                customer_id, date = line.split(',')\n                qualifying_data.append([int(customer_id), current_movie_id])\n    return pd.DataFrame(qualifying_data, columns=['Cust_Id', 'Movie_Id'])\n\nqualifying_data = read_qualifying_file('/kaggle/input/netflix-prize-data/qualifying.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get unique user IDs from the qualifying dataset\nunique_user_ids = qualifying_data['Cust_Id'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate predictions for the qualifying set\nqualifying_predictions = []\nfor user_id in unique_user_ids:\n    top_n_recommendations, top_n_scores = get_top_n_recommendations(algo, user_id, all_movie_ids, n=10)\n    for movie_id, score in zip(top_n_recommendations, top_n_scores):\n        qualifying_predictions.append([user_id, movie_id, score])\n\nqualifying_predictions_df = pd.DataFrame(qualifying_predictions, columns=['Cust_Id', 'Movie_Id', 'Estimated_Score'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge with movie titles\nqualifying_predictions_df = qualifying_predictions_df.merge(movie_titles, on='Movie_Id')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the results for a specific user (for example, user_id = 712664)\nspecific_user_predictions = qualifying_predictions_df[qualifying_predictions_df['Cust_Id'] == 712664]\nprint(f\"Top 10 movie recommendations for user {user_id}:\")\nprint(specific_user_predictions[['Movie_Id', 'Year', 'Name', 'Estimated_Score']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}